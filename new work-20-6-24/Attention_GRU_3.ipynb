{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVpc9kP4VoK9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import RobustScaler, PowerTransformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjMae04DVt3H",
        "outputId": "3da4cc62-55e2-464d-e80d-dfa3e8336a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Qz6Xr-OyDRH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name1 = '/content/drive/MyDrive/EXP/SHAP/Train/V_train_bert_mean4.csv'\n",
        "file_name2 = '/content/drive/MyDrive/EXP/SHAP/Test/V_test_bert_mean4.csv'\n",
        "train_data = pd.read_csv(file_name1)\n",
        "test_data = pd.read_csv(file_name2)"
      ],
      "metadata": {
        "id": "phF2zktpVvS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvchtw9Scntn",
        "outputId": "3f9295a0-b93e-41f5-b1ae-6ad38ef34042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4599, 1025)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "g1TT_4SgVwzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ratio = 0.05  # 5% of the training data is used as validation\n",
        "val_size = int(len(train_data) * val_ratio)\n",
        "train_size = len(train_data) - val_size\n",
        "\n",
        "train_dataset_full = TensorDataset(torch.tensor(train_data.drop('target', axis=1).values, dtype=torch.float32),\n",
        "                                   torch.tensor(train_data['target'].values, dtype=torch.float32).view(-1, 1))\n",
        "\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset_full, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "test_dataset = TensorDataset(torch.tensor(test_data.drop('target', axis=1).values, dtype=torch.float32),\n",
        "                             torch.tensor(test_data['target'].values, dtype=torch.float32).view(-1, 1))\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "HDXYjVmPVygT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, feature_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.feature_dim = feature_dim\n",
        "        self.att_weights = nn.Parameter(torch.Tensor(1, feature_dim))\n",
        "        nn.init.xavier_uniform_(self.att_weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        att_scores = torch.matmul(x, self.att_weights.T)\n",
        "        att_weights = torch.softmax(att_scores, dim=1)\n",
        "        attended = x * att_weights\n",
        "        return torch.sum(attended, dim=1)\n",
        "\n",
        "\n",
        "class AttModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(AttModel, self).__init__()\n",
        "        self.attention = Attention(input_size)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.bn = nn.BatchNorm1d(hidden_size)\n",
        "        self.dropout = nn.Dropout(0.7)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        att = self.attention(x).unsqueeze(0)\n",
        "        out = self.bn(att)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "\n",
        "model = AttModel(input_size=1024, hidden_size=64, output_size=1)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.999), eps=1e-8)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "j1K9DK-yV0cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracies = []\n",
        "def train_model(model, train_loader, val_loader, test_loader, optimizer, criterion, num_epochs , scheduler):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item()\n",
        "            predicted_train = torch.round(outputs)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted_train == labels).sum().item()\n",
        "\n",
        "        train_accuracy = correct_train / total_train * 100\n",
        "        scheduler.step()\n",
        "\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                total_val_loss += loss.item()\n",
        "                predicted_val = torch.round(outputs)\n",
        "                total_val += labels.size(0)\n",
        "                correct_val += (predicted_val == labels).sum().item()\n",
        "\n",
        "        val_accuracy = correct_val / total_val * 100\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
        "              f'Train Loss: {total_train_loss / len(train_loader):.4f}, '\n",
        "              f'Train Accuracy: {train_accuracy:.2f}%, '\n",
        "              f'Validation Loss: {total_val_loss / len(val_loader):.4f}, '\n",
        "              f'Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "def test_model(model):\n",
        "      model.eval()\n",
        "      correct = 0\n",
        "      total = 0\n",
        "\n",
        "      with torch.no_grad():\n",
        "          for inputs, labels in test_loader:\n",
        "              outputs = model(inputs)\n",
        "              predicted = torch.round(outputs)\n",
        "              total += labels.size(0)\n",
        "              correct += (predicted == labels).sum().item()\n",
        "\n",
        "      accuracy = correct / total * 100\n",
        "      test_accuracies.append(accuracy)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, confusion_matrix, precision_score, recall_score, f1_score, matthews_corrcoef\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            predicted_probs = outputs.squeeze().detach().cpu().numpy()\n",
        "            predictions.extend(predicted_probs)\n",
        "            true_labels.extend(labels.squeeze().detach().cpu().numpy())\n",
        "\n",
        "    predicted_labels = [1 if x > 0.5 else 0 for x in predictions]\n",
        "\n",
        "    auc_score = roc_auc_score(true_labels, predictions)\n",
        "\n",
        "    precision = precision_score(true_labels, predicted_labels)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(true_labels, predicted_labels).ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "    sensitivity = recall\n",
        "\n",
        "    mcc = matthews_corrcoef(true_labels, predicted_labels)\n",
        "\n",
        "    precision_points, recall_points, _ = precision_recall_curve(true_labels, predictions)\n",
        "    aupr = auc(recall_points, precision_points)\n",
        "\n",
        "    # Compute True Positive Rate (TPR) and False Positive Rate (FPR)\n",
        "    tpr = tp / (tp + fn)\n",
        "    fpr = fp / (fp + tn)\n",
        "\n",
        "    # Print confusion matrix\n",
        "    confusion_matrix_result = confusion_matrix(true_labels, predicted_labels)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix_result)\n",
        "\n",
        "    metrics = {\n",
        "        'AUC': auc_score,\n",
        "        'Specificity': specificity,\n",
        "        'Sensitivity': sensitivity,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'MCC': mcc,\n",
        "        'AUPR': aupr,\n",
        "        'TPR': tpr,\n",
        "        'FPR': fpr,\n",
        "        'Confusion_Matrix': confusion_matrix_result\n",
        "    }\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "z6th45_Vm1th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 101):\n",
        "    model1 = model  # Assuming you have defined these variables earlier\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01 , betas=(0.9, 0.999), eps=1e-8)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "    train_model(model1, train_loader, val_loader, test_loader, optimizer, criterion, i , scheduler)\n",
        "    print('-----------------------------------------------------------------------------------------------------------------------')\n",
        "    test_model(model1)\n",
        "    print(test_accuracies)\n",
        "    print(evaluate_model(model1, test_loader))\n",
        "    print('-----------------------------------------------------------------------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "lWZfehh3m3Of",
        "outputId": "6e9850d6-5122-4678-85aa-3f18d52432f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 16])",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-51090124061c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-----------------------------------------------------------------------------------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-113-5da8b7022a1d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, test_loader, optimizer, criterion, num_epochs, scheduler)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-112-6f214b4d30f0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0matt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure the output is 2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2505\u001b[0m         )\n\u001b[1;32m   2506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2507\u001b[0;31m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2509\u001b[0m     return torch.batch_norm(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2475\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected more than 1 value per channel when training, got input size {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 16])"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_value = max(test_accuracies)\n",
        "print(\"Maximum Accuracy:\", max_value)\n",
        "\n",
        "min_value = min(test_accuracies)\n",
        "print(\"Minimum Accuracy:\", min_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zx9HzXBQ6X_-",
        "outputId": "c81a1ef3-95cf-490e-c615-83236dfbf742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum Accuracy: 88.14814814814815\n",
            "Minimum Accuracy: 84.07407407407408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_test_accuracies = sorted(enumerate(test_accuracies), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "for index, accuracy in sorted_test_accuracies:\n",
        "    print(f\"Index: {index+1}, Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8BCioCr6Zv5",
        "outputId": "16005db6-4972-4bd7-d12c-a4cd9ca7328d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 55, Test Accuracy: 88.15%\n",
            "Index: 79, Test Accuracy: 88.15%\n",
            "Index: 29, Test Accuracy: 88.02%\n",
            "Index: 65, Test Accuracy: 87.90%\n",
            "Index: 89, Test Accuracy: 87.90%\n",
            "Index: 69, Test Accuracy: 87.78%\n",
            "Index: 58, Test Accuracy: 87.65%\n",
            "Index: 59, Test Accuracy: 87.65%\n",
            "Index: 93, Test Accuracy: 87.65%\n",
            "Index: 28, Test Accuracy: 87.53%\n",
            "Index: 41, Test Accuracy: 87.41%\n",
            "Index: 45, Test Accuracy: 87.41%\n",
            "Index: 21, Test Accuracy: 87.28%\n",
            "Index: 22, Test Accuracy: 87.28%\n",
            "Index: 70, Test Accuracy: 87.28%\n",
            "Index: 87, Test Accuracy: 87.28%\n",
            "Index: 18, Test Accuracy: 87.16%\n",
            "Index: 36, Test Accuracy: 87.16%\n",
            "Index: 38, Test Accuracy: 87.16%\n",
            "Index: 61, Test Accuracy: 87.16%\n",
            "Index: 94, Test Accuracy: 87.16%\n",
            "Index: 98, Test Accuracy: 87.16%\n",
            "Index: 14, Test Accuracy: 87.04%\n",
            "Index: 49, Test Accuracy: 87.04%\n",
            "Index: 60, Test Accuracy: 87.04%\n",
            "Index: 88, Test Accuracy: 87.04%\n",
            "Index: 92, Test Accuracy: 87.04%\n",
            "Index: 10, Test Accuracy: 86.91%\n",
            "Index: 20, Test Accuracy: 86.91%\n",
            "Index: 39, Test Accuracy: 86.91%\n",
            "Index: 90, Test Accuracy: 86.91%\n",
            "Index: 4, Test Accuracy: 86.79%\n",
            "Index: 9, Test Accuracy: 86.79%\n",
            "Index: 13, Test Accuracy: 86.79%\n",
            "Index: 66, Test Accuracy: 86.79%\n",
            "Index: 83, Test Accuracy: 86.79%\n",
            "Index: 99, Test Accuracy: 86.79%\n",
            "Index: 30, Test Accuracy: 86.67%\n",
            "Index: 42, Test Accuracy: 86.67%\n",
            "Index: 43, Test Accuracy: 86.67%\n",
            "Index: 51, Test Accuracy: 86.67%\n",
            "Index: 53, Test Accuracy: 86.67%\n",
            "Index: 81, Test Accuracy: 86.67%\n",
            "Index: 91, Test Accuracy: 86.67%\n",
            "Index: 7, Test Accuracy: 86.54%\n",
            "Index: 16, Test Accuracy: 86.54%\n",
            "Index: 24, Test Accuracy: 86.54%\n",
            "Index: 31, Test Accuracy: 86.54%\n",
            "Index: 50, Test Accuracy: 86.54%\n",
            "Index: 64, Test Accuracy: 86.54%\n",
            "Index: 32, Test Accuracy: 86.42%\n",
            "Index: 40, Test Accuracy: 86.42%\n",
            "Index: 48, Test Accuracy: 86.42%\n",
            "Index: 54, Test Accuracy: 86.42%\n",
            "Index: 73, Test Accuracy: 86.42%\n",
            "Index: 96, Test Accuracy: 86.42%\n",
            "Index: 26, Test Accuracy: 86.30%\n",
            "Index: 77, Test Accuracy: 86.30%\n",
            "Index: 80, Test Accuracy: 86.30%\n",
            "Index: 100, Test Accuracy: 86.30%\n",
            "Index: 11, Test Accuracy: 86.17%\n",
            "Index: 33, Test Accuracy: 86.17%\n",
            "Index: 37, Test Accuracy: 86.17%\n",
            "Index: 44, Test Accuracy: 86.17%\n",
            "Index: 52, Test Accuracy: 86.17%\n",
            "Index: 57, Test Accuracy: 86.17%\n",
            "Index: 62, Test Accuracy: 86.17%\n",
            "Index: 63, Test Accuracy: 86.17%\n",
            "Index: 72, Test Accuracy: 86.17%\n",
            "Index: 86, Test Accuracy: 86.17%\n",
            "Index: 5, Test Accuracy: 86.05%\n",
            "Index: 12, Test Accuracy: 86.05%\n",
            "Index: 23, Test Accuracy: 86.05%\n",
            "Index: 27, Test Accuracy: 86.05%\n",
            "Index: 34, Test Accuracy: 86.05%\n",
            "Index: 35, Test Accuracy: 86.05%\n",
            "Index: 68, Test Accuracy: 86.05%\n",
            "Index: 75, Test Accuracy: 86.05%\n",
            "Index: 85, Test Accuracy: 86.05%\n",
            "Index: 97, Test Accuracy: 86.05%\n",
            "Index: 17, Test Accuracy: 85.93%\n",
            "Index: 74, Test Accuracy: 85.93%\n",
            "Index: 82, Test Accuracy: 85.93%\n",
            "Index: 2, Test Accuracy: 85.80%\n",
            "Index: 3, Test Accuracy: 85.80%\n",
            "Index: 46, Test Accuracy: 85.80%\n",
            "Index: 67, Test Accuracy: 85.68%\n",
            "Index: 71, Test Accuracy: 85.68%\n",
            "Index: 95, Test Accuracy: 85.68%\n",
            "Index: 6, Test Accuracy: 85.56%\n",
            "Index: 47, Test Accuracy: 85.56%\n",
            "Index: 56, Test Accuracy: 85.56%\n",
            "Index: 78, Test Accuracy: 85.56%\n",
            "Index: 84, Test Accuracy: 85.43%\n",
            "Index: 8, Test Accuracy: 85.31%\n",
            "Index: 15, Test Accuracy: 85.19%\n",
            "Index: 19, Test Accuracy: 85.19%\n",
            "Index: 25, Test Accuracy: 85.19%\n",
            "Index: 76, Test Accuracy: 85.19%\n",
            "Index: 1, Test Accuracy: 84.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JCjuvS5lughw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run these two cells"
      ],
      "metadata": {
        "id": "1soRjwM3ugsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 24\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_train_loss += loss.item()\n",
        "    scheduler.step()\n",
        "\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Train Loss: {total_train_loss / len(train_loader):.4f}, '\n",
        "          f'Validation Loss: {total_val_loss / len(val_loader):.4f}')"
      ],
      "metadata": {
        "id": "uJBEZ4-Jt2YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, matthews_corrcoef, precision_score, recall_score, f1_score, \\\n",
        "    accuracy_score, roc_curve, precision_recall_curve\n",
        "\n",
        "true_labels = []\n",
        "predicted_probabilities = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        predicted_probabilities.extend(outputs.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "true_labels = np.array(true_labels)\n",
        "predicted_probabilities = np.array(predicted_probabilities)\n",
        "\n",
        "auc = roc_auc_score(true_labels, predicted_probabilities)\n",
        "\n",
        "mcc = matthews_corrcoef(true_labels, np.round(predicted_probabilities))\n",
        "\n",
        "precision = precision_score(true_labels, np.round(predicted_probabilities))\n",
        "recall = recall_score(true_labels, np.round(predicted_probabilities))\n",
        "f1 = f1_score(true_labels, np.round(predicted_probabilities))\n",
        "\n",
        "accuracy = accuracy_score(true_labels, np.round(predicted_probabilities)) * 100\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(true_labels, predicted_probabilities)\n",
        "sensitivity = tpr\n",
        "specificity = 1 - fpr\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(true_labels, predicted_probabilities)\n",
        "aupr = np.trapz(precision, recall)\n",
        "\n",
        "\n",
        "print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "print(f'AUC: {auc:.4f}')\n",
        "print(f'MCC: {mcc:.4f}')\n",
        "print(f'Precision: {precision.mean():.4f}')  # Average precision\n",
        "print(f'Recall: {recall.mean():.4f}')  # Average recall\n",
        "print(f'F1-score: {f1:.4f}')\n",
        "print(f'Sensitivity: {sensitivity.mean():.4f}')  # Average sensitivity\n",
        "print(f'Specificity: {specificity.mean():.4f}')  # Average specificity\n",
        "print(f'AUPR: {aupr:.4f}')"
      ],
      "metadata": {
        "id": "VIzxiJvct2fB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}